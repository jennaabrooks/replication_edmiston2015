<!DOCTYPE html>
<html>
 <head>
    <title> Words Special Experiment</title>
    <script src="https://unpkg.com/jspsych@8.0.0"></script>
    <script src="https://unpkg.com/@jspsych/plugin-html-keyboard-response@2.0.0"></script>
    <script src="https://unpkg.com/@jspsych/plugin-image-keyboard-response@2.0.0"></script>
    <script src="https://unpkg.com/@jspsych/plugin-audio-keyboard-response@2.0.0"></script>
    <script src="https://unpkg.com/@jspsych/plugin-preload@2.0.0"></script>
    <script src="https://unpkg.com/@jspsych/plugin-audio-button-response@2.0.0"></script>
    <script src="https://unpkg.com/@jspsych/plugin-html-button-response@1.2.0"></script>
    <script src="https://unpkg.com/@jspsych-contrib/plugin-pipe"></script>
    <link href="https://unpkg.com/jspsych@8.0.0/css/jspsych.css" rel="stylesheet" type="text/css" />
    <script src="https://unpkg.com/jspsych@latest/jspsych.js"></script>
    <script src="https://unpkg.com/@jspsych/plugin-fullscreen@2.0.0"></script>
    <style>
        #trial-counter {
            position: fixed;
            bottom: 10px;
            width: 100%;
            text-align: center;
            font-size: 18px;
            color: #000; /* Ensure the font color contrasts with the background */
            background-color: #fff; /* Temporary background for visibility */
            padding: 5px;
        }
      </style>
 </head>
 <body>

 <div id="trial-counter"></div>

 <script> 

var jsPsych = initJsPsych({
    show_progress_bar: true,
    auto_update_progress_bar: false,
    /*
    on_finish: function() {
        jsPsych.data.displayData();
        jsPsych.data.get().filter({part: 'result'}).localSave('csv', 'experiment_data.csv'); // download result to local
    },
    */
});

//create timeline
var timeline = [];

//set number of trials
const N_PRACTICE = 2; // 6;
const N_TRIALS = 2; // 384;

// list all stims to use
const IMAGE_PATH_LIST = [
    'experiment/stimuli/pictures/bird_hawk_1.jpg', 
    'experiment/stimuli/pictures/bird_hawk_2.jpg',
    'experiment/stimuli/pictures/bird_song_1.jpg',
    'experiment/stimuli/pictures/bird_song_2.jpg',
    'experiment/stimuli/pictures/dog_rott_1.jpg',
    'experiment/stimuli/pictures/dog_rott_2.jpg',
    'experiment/stimuli/pictures/dog_york_1.jpg',
    'experiment/stimuli/pictures/dog_york_2.jpg',
    'experiment/stimuli/pictures/drum_bongo_1.jpg',
    'experiment/stimuli/pictures/drum_bongo_2.jpg',
    'experiment/stimuli/pictures/drum_kit_1.jpg',
    'experiment/stimuli/pictures/drum_kit_2.jpg',
    'experiment/stimuli/pictures/guitar_acoustic_1.jpg', 
    'experiment/stimuli/pictures/guitar_acoustic_2.jpg',
    'experiment/stimuli/pictures/guitar_electric_1.jpg',
    'experiment/stimuli/pictures/guitar_electric_2.jpg',
    'experiment/stimuli/pictures/motor_dirt_1.jpg',
    'experiment/stimuli/pictures/motor_dirt_2.jpg', 
    'experiment/stimuli/pictures/motor_harley_1.jpg', 
    'experiment/stimuli/pictures/motor_harley_2.jpg', 
    'experiment/stimuli/pictures/phone_cell_1.jpg',
    'experiment/stimuli/pictures/phone_cell_2.jpg',
    'experiment/stimuli/pictures/phone_rotary_1.jpg',
    'experiment/stimuli/pictures/phone_rotary_2.jpg'];

const SOUND_PATH_LIST = [
    'experiment/stimuli/sounds/bird_label_A.wav',
    'experiment/stimuli/sounds/bird_label_B.wav', 
    'experiment/stimuli/sounds/bird_sound_A.wav', 
    'experiment/stimuli/sounds/bird_sound_B.wav',
    'experiment/stimuli/sounds/bleep.wav', // these may be an issue
    'experiment/stimuli/sounds/buzz.wav', // we might have an issue with this
    'experiment/stimuli/sounds/dog_label_A.wav', 
    'experiment/stimuli/sounds/dog_label_B.wav',
    'experiment/stimuli/sounds/dog_sound_A.wav', 
    'experiment/stimuli/sounds/dog_sound_B.wav',
    'experiment/stimuli/sounds/drum_label_A.wav',
    'experiment/stimuli/sounds/drum_label_B.wav',
    'experiment/stimuli/sounds/drum_sound_A.wav',
    'experiment/stimuli/sounds/drum_sound_B.wav',
    'experiment/stimuli/sounds/guitar_label_A.wav',
    'experiment/stimuli/sounds/guitar_label_B.wav',
    'experiment/stimuli/sounds/guitar_sound_A.wav',
    'experiment/stimuli/sounds/guitar_sound_B.wav',
    'experiment/stimuli/sounds/motor_label_A.wav',
    'experiment/stimuli/sounds/motor_label_B.wav',
    'experiment/stimuli/sounds/motor_sound_A.wav', 
    'experiment/stimuli/sounds/motor_sound_B.wav',
    'experiment/stimuli/sounds/phone_label_A.wav',
    'experiment/stimuli/sounds/phone_label_B.wav',
    'experiment/stimuli/sounds/phone_sound_A.wav',
    'experiment/stimuli/sounds/phone_sound_B.wav'];

const ADDITIONAL_AUDIO_PATH_LIST = [
    'experiment/stimuli/sounds/letter_f.wav',
    'experiment/stimuli/sounds/letter_j.wav',
];

//preloaded all images from stimuli folder  
var preload = {
  type: jsPsychPreload,
  images: IMAGE_PATH_LIST, 
  audio: [...SOUND_PATH_LIST, ...ADDITIONAL_AUDIO_PATH_LIST],
};
timeline.push(preload); 

// define consent form
const consent_form = {
    type: jsPsychHtmlButtonResponse,
    stimulus: `<h2>Consent form</h2>
               <p>You are being invited to participate in a research study titled <q>Reproducibility of Psychological Science and Instruction.</q> This study is being done by Dr. Bria Long from UC San Diego and associated graduate students in Experimental Methods course. You were selected to participate in this study because you are an adult in the U.S. and have been a represented population in previous psychology studies.</p>
               <p>The purpose of this study is to better understand how well previously published studies in the psychological field replicate online and with different populations. Your participation in this research should last approximately 5-30 minutes. If you agree to take part in this study, you may be asked to view a set of stimuli, including pictures, sounds, and/or written text and then giving some responses via key-presses, verbally, or with paper-and-pencil. We may also observe your choices or preferences among an array of stimuli.  These stimuli will be taken directly from or closely adapted from studies that already exist in the published psychological literature. Stimuli will include, e.g., pictures of objects and human faces, audio and video clips, short text passages, etc. None of the stimuli will be disturbing, threatening, or offensive. The online and in-person experiments described in this protocol will take no more than 30 minutes. An example game you might play would be to click on an image on the screen that matches a word you hear being said out loud. Your total expected time commitment for this study is between 5-30 minutes, and is specified in the study description.</p>
               <p>Your participation in this study is completely voluntary and you can withdraw at any time. Choosing not to participate or withdrawing will result in no penalty or loss of benefits to which you are entitled. You are free to skip any question that you choose.</p>
               <p>We will not be asking for any personally identifying information, and we will handle responses as confidentially as possible. Your SONA or Prolific IDs will never be tied to your responses on this survey. However, we cannot guarantee the confidentiality of information transmitted over the Internet. To minimize this risk, data containing anything that might be personally identifiable (e.g. Prolific IDs or IP addresses) will be encrypted on transfer and storage and will only be accessible to qualified lab personnel. We will be keeping data collected as part of this experiment indefinitely. This anonymized data (containing neither Prolific IDs nor IP addresses) may be shared with the scientific community or with other participants to be used as stimuli in future studies.</p>
               <p>If you have questions about this project or if you have a research-related problem, you may contact the researcher(s),  Dr. Bria Long, brlong@ucsd.edu. If you have any questions concerning your rights as a research subject, you may contact the UC San Diego Office of IRB Administration at irb@ucsd.edu or 858-246-4777.</p>
               <p>By participating in this research you are indicating that you are at least 18 years old, have read this consent form, and agree to participate in this research study. Please keep this consent form for your records.</p>`,
    choices: ['I consent'],
    button_html: ['<button class="jspsych-btn">%choice%</button>']

};
timeline.push(consent_form);

//define welcome message trial 
var welcome = {
    type: jsPsychHtmlKeyboardResponse,
    stimulus: `
        <div style="text-align: center; line-height: 1.6;">
            <p><strong>Welcome to the experiment.</strong></p>
            <p>There are ${N_TRIALS} trials (with ${N_PRACTICE} practice trials). This will take about 20 minutes to complete.</p>
            <p><strong>This experiment requires audio.</strong> Please increase your volume to ensure that you can hear all audio cues. We recommend completing these trials in a quiet setting. Headphones are strongly recommended.</p>
            <p><strong>Press any key to begin.</strong></p>
        </div>
    `,
    on_start: function() {
        jsPsych.progressBar.progress = 0;
    },
};
// add the welcome trial to the timeline variable
timeline.push(welcome);

 // function to update trial counter
function updateTrialCounter() {
    document.getElementById('trial-counter').textContent = `Trial ${trial_count} of ${N_TRIALS}`;
}

// before practice: test the audio and keyboard
const test_audio_keyboard_intro = {
    type: jsPsychHtmlKeyboardResponse,
    stimulus: `
        <div style="text-align: center; line-height: 1.6;">
            <p>Before we start, Ensure that your laptop audio is turned on,</p>
            <p>And you can use your keyboard.</p>
            <p>Now we will test your computer audio and keyboard.</p>
            <p><strong>Press any key to begin.</strong></p>
        </div>
    `,
};
timeline.push(test_audio_keyboard_intro);

function create_test_audio(letter) {
    var test_audio_and_key = {
        timeline: [{
            type: jsPsychAudioKeyboardResponse,
            stimulus: `experiment/stimuli/sounds/letter_${letter}.wav`,
            prompt: `<div style="text-align: center; line-height: 1.6;">
                <p>Press the button you heard</p>
                <p>(If you need to replay the sound, press <strong>'R'</strong>)</p>
            </div>`,
            choices: ['r', letter]
        }],
        loop_function: function(data){
            console.log(data);
            if(data.values()[0].response === 'r'){
                return true; // loop again!
            } else {
                return false; // continue
            }
        }
    }
    return test_audio_and_key;
}

// test f button
const letter_f_test = create_test_audio("f");
timeline.push(letter_f_test);

// test j button
const letter_j_test = create_test_audio("j");
timeline.push(letter_j_test);

// enter full screen mode
const enter_fullscreen = {
    type: jsPsychFullscreen,
    fullscreen_mode: true
};
timeline.push(enter_fullscreen);

/**
 * The following are functions defined to load stimuli
 */

// function for loading the correct stims
function create_cue_to_play(cue_name) {
    /**
     * @param {string} cue_name - the auditory/label cue to play
     */ 
    // modified from Jenna's code
    var sound = {
        type:jsPsychAudioButtonResponse,
        stimulus: `experiment/stimuli/sounds/${cue_name}.wav`, 
        choices: [], //Do not add choices here, we don't want the participant to respond until after image. Need this line for code to run. 
        trial_ends_after_audio: true // Ends trial automatically after audio finishes
    };
    return sound;
}

// function for loading the correct stims
function create_img_display(img_name, correct_response) {
    /**
     * @param {string} img_name - the picture to show
     */ 
    // modified from Jenna's code
    var img = {
        type: jsPsychImageKeyboardResponse,
        stimulus: `experiment/stimuli/pictures/${img_name}.jpg`,
        choices: ['f', 'j'],
        prompt: `
            <div style="display: block; text-align: center; margin-bottom: 100px;">
                Does this image match the auditory cue?<br>
                Press <strong> F </strong> for yes, <strong> J </strong> for no.
            </div>
        `,
        response_ends_trial: true, // Keeps image visible until response
        data: { 
            part: 'img',
            correct_response: correct_response,
        },
        
        /* comment out: use default trial count bar provided by jspsych
        on_start: function() {
            updateTrialCounter(); // Update the trial counter display first (MODIFIED)
            trial_count++;        // Increment trial count after updating display (MODIFIED)
        }
        */
    };

    return img;
}

function process_all_imgs() {
    /**
     * This is to load all categories to be tested (bird, dog...)
     * for each image, we want to have its category, subtype, and version number
     */
    // firstly, get all images
    var jpg_files = IMAGE_PATH_LIST.map(path => path.split('/').pop())

    // then parse the jpg file name: catgeory, subtype and version
    var parsed = jpg_files.map(file => {
        var fname = file.substring(0, file.lastIndexOf('.'));
        var [category, subtype, version] = fname.split('_');
        return {
          fname: fname,
          category: category,
          subtype: subtype,
          version: version
        };
    });

    return parsed;
}

// Parse sound details, excluding bleep and buzz
function process_all_sounds() {
    var parsed = SOUND_PATH_LIST
        .filter(path => !path.includes('bleep') && !path.includes('buzz')) // MODIFICATION: Exclude bleep and buzz sounds
        .map(path => {
            var file = path.split('/').pop();
            var fname = file.substring(0, file.lastIndexOf('.'));
            var [category, subtype, version] = fname.split('_');
            return {
                fname: fname,
                category: category,
                subtype: subtype,
                version: version
            };
        });

    return parsed;
}

// collect all images/categories to test
const all_img_stims = process_all_imgs();
const all_sound_stims = process_all_sounds();

// Fixation cross trial
const fixation_cross = {
    type: jsPsychHtmlKeyboardResponse,
    stimulus: '<div style="font-size: 48px;">+</div>', // You can change the symbol or style as needed
    choices: "NO_KEYS", // Prevents any key from being pressed
    trial_duration: 250 // Display for 250 ms
};
// Delay trial of 1000 ms (1 second) after audio ends
const delay = {
    type: jsPsychHtmlKeyboardResponse,
    stimulus: '', // Blank screen
    choices: "NO_KEYS", // Prevents any response
    trial_duration: 1000 // 1-second delay
};

// Feedback trial
const feedback_trial = {
    type: jsPsychAudioButtonResponse,
    stimulus: function() {
        var last_trial_correct = jsPsych.data.get().last(1).values()[0].response === 
                                 jsPsych.data.get().last(1).values()[0].correct_response;
        return last_trial_correct ? 'experiment/stimuli/sounds/bleep.wav' : 'experiment/stimuli/sounds/buzz.wav';
    },
    choices: [],
    trial_ends_after_audio: true
};

// Data aggregation: hold the preprocess data at the end.
const post_trial_process = {
    type: jsPsychHtmlKeyboardResponse,
    stimulus: '',  
    choices: "NO_KEYS",  
    trial_duration: 0,
    data: {part: "result"},
    on_finish: function() {
        // update progress bar
        var curr_progress = jsPsych.progressBar.progress;
        jsPsych.progressBar.progress = curr_progress + (1/(N_PRACTICE+N_TRIALS));
    }
};

// Helper function to create Y (match) and N (mismatch) trials
function create_trial(img, sound, correct_response, exp_part) {
    let cue = create_cue_to_play(sound.fname);
    let img_display = create_img_display(img.fname, correct_response);

    // group all phases into one nested trial
    let single_word_trial = {
        timeline: [fixation_cross, cue, delay, img_display, feedback_trial, post_trial_process],
        on_timeline_finish: function () {
            const lastTrialData = jsPsych.data.getLastTimelineData();
            // console.log(lastTrialData);
            const img_data = lastTrialData.filter({part: 'img'}).values()[0];
            let response_data = lastTrialData.filter({part: 'result'}).values()[0];
            Object.keys(response_data).forEach(key => delete response_data[key]); // clear it
            
            // save result
            response_data.rt = img_data.rt;
            response_data.correct_response = img_data.correct_response;
            response_data.response = img_data.response;
            response_data.time_elapsed = img_data.time_elapsed;
            
            // add img information
            response_data.img_fname = img.fname;
            response_data.img_category = img.category;
            response_data.img_subtype = img.subtype;
            response_data.img_version = img.version;

            // add sound information
            response_data.sound_fname = sound.fname;
            response_data.sound_category = sound.category;
            response_data.sound_subtype = sound.subtype;
            response_data.sound_version = sound.version;
            // console.log(response_data);

            // mark whether it's practice or actual trials
            response_data.exp_part = exp_part;

            // mark data to collect at the end
            response_data.part = "result";
        }
    };

    return single_word_trial;
    // return [fixation_cross, cue, delay, img_display, feedback_trial];
}

// Generate "Y trials" and "N trials"
function generate_trials(N_trials, exp_part) {
    var trials = [];
    let yes_trial_repeat = 2;

    // Generate 96 "Y trials" for each category and duplicate once for 192 trials
    all_img_stims.forEach(img => {
        let match_sounds = all_sound_stims.filter(sound => sound.category === img.category);
        match_sounds.forEach(sound => {
            for (let i=0;i<yes_trial_repeat;i++) {
                // safer way to repeat (than using jsPsych.randomization.repeat)
                let new_trial = create_trial(img, sound, 'f', exp_part);
                trials.push(new_trial);
            }
        });
    });

    // Generate 192 "N trials" with mismatching categories
    // also balance label/sound
    let n_mismatch_each_sound = 8;
    for (let i=0;i < all_sound_stims.length; i++) {
        let sound = all_sound_stims[i];
        let mismatch_imgs = all_img_stims.filter(img => img.category !== sound.category);
        let imgs = jsPsych.randomization.sampleWithoutReplacement(mismatch_imgs, n_mismatch_each_sound);
        imgs.forEach(img => {
            let new_trial = create_trial(img, sound, 'j', exp_part);
            trials.push(new_trial);
        });
    }

    // console.log(trials.length);

    // shuffle
    trials = jsPsych.randomization.shuffle(trials);

    // select the first N_trials
    trials = trials.slice(0, N_trials);

    // flatten: create one big list
    // trials = trials.flat();
    
    return trials;
}

/* PRACTICE TRIALS */
// Instructions
const instructions = {
    type: jsPsychHtmlButtonResponse,
    stimulus: `<h2>Instructions & Practice</h2>
               <p>Your task is to decide as quickly and accurately as possible if the auditory cue you hear matches the image you see.</p>
               <p> First you will hear an auditory cue, then you will see an image. </p>
               <p>Press letter "F", <strong>yes</strong> if the auditory cue matches the image you saw, and letter "J", <strong>no</strong> if it does not.</p>`,
    choices: ['Start Practice'],
    button_html: ['<button class="jspsych-btn">%choice%</button>']

};
timeline.push(instructions);

// generate and add test trials
const practice_trials = generate_trials(N_PRACTICE, 'practice');
timeline.push(...practice_trials);

/* ACTUAL TRIALS */
// instructions
const actual_trials_instructions = {
    type: jsPsychHtmlButtonResponse,
    stimulus: `<h2>Starting Actual Trials</h2>
               <p>Your task is to decide as quickly and accurately as possible if auditory cue you hear matches the image you see.</p>
               <p> First you will hear an auditory cue, then you will see an image. </p>
               <p>Press letter "F", yes if it matches the image you saw, and letter "J", no if it does not.</p>`,
    choices: ['Start Actual Test'],
    button_html: ['<button class="jspsych-btn">%choice%</button>']
};
timeline.push(actual_trials_instructions);

// generate actual trials
const trials = generate_trials(N_TRIALS, 'actual');
timeline.push(...trials);

// osf data pipeline
const subject_id = jsPsych.randomization.randomID(10);
// const subject_id = "debug"; // DEBUG
const filename = `${subject_id}.csv`;

const save_data = {
    type: jsPsychPipe,
    action: "save",
    experiment_id: "ubx08eg1SvJC",
    filename: filename,
    data_string: function () { 
        jsPsych.data.addProperties({ID: subject_id});
        const selected_data = jsPsych.data.get().filter({part:"result"}).csv();
        return selected_data;
    },
};

timeline.push(save_data);

// a debriefing at the end
var end_block = {
    type: jsPsychHtmlButtonResponse,
    stimulus: `
        <p>Data uploaded.</p>
        <p>Thank you for completing the experiment!</p>
        <p>This experiment aims to replicate the findings of <q>What makes words special? Words as unmotivated cues</q> (Edmiston et al., 2015). The original study examines how verbal labels and environmental sounds activate conceptual knowledge.</p>
        <p>If you have questions about this project or if you have a research-related problem, you may contact the researcher(s),  Dr. Bria Long, brlong@ucsd.edu. If you have any questions concerning your rights as a research subject, you may contact the UC San Diego Office of IRB Administration at irb@ucsd.edu or 858-246-4777.</p>
        <p>Click the button below to return to Prolific.</p>
    `,
    choices: ['Finish'],
    button_html: ['<button class="jspsych-btn">%choice%</button>']
};

timeline.push(end_block);



// Start the experiment
jsPsych.run(timeline);

</script>
</html>
