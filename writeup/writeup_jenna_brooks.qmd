---
title: "Replication of Study What makes words special? Words as unmotivated cues (2015, Cognition)"
author: "Jenna Brooks(j8brooks@ucsd.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
format:
  html:
    toc: true
    toc_depth: 3
---

<!-- Replication reports should all use this template to standardize reporting across projects.  These reports will be public supplementary materials that accompany the summary report(s) of the aggregate results. -->

## Introduction

This study aimed to explore why verbal labels, such as the words "dog" or "guitar," activate conceptual knowledge more effectively than environmental sounds associated with these objects, such as the bark of a dog or the strum of a guitar. I chose this topic because it intersects with my interests in language learning and auditory perception. This study finds that verbal labels (or words) are more effective than sounds in activating abstract category concepts because labels act as "unmotivated cues," broadly representing a category without specific reference to particular instances. In contrast, sounds are "motivated cues" that link directly to specific sources or instances, limiting their effectiveness in promoting conceptual abstraction. This difference is highlighted by experiments showing that words activate category-level knowledge more selectively than environmental sounds.

In this experiment, participants will be presented with either a verbal representation or  environmental sound for the following categories: bird, dog, drum, guitar, motorcycle, and phone. Participants are presented with an auditory cue (either a word or sound) and a picture presented 1 second after the auditory input is made. Participants are tested on how quickly and accurately they can determine if the picture presented matches the auditory cue they received. They will use a yes or no button on the computer screen. Potential challenges of this study could be sound quality of the environmental sounds to ensure they are clearly recognizable. Additionally, finding a diverse group of participants for this study could be a challenge. 

## Methods

### Power Analysis 
The use of linear mixed-effects models (lmer) with a complex structure limits our ability to perform a straightforward power analysis. This constraint makes it difficult to estimate effect sizes accurately, as we would in a simpler within-participants t-test design. We defaulted to expanding the sample size to 2.5 times the initial estimate. This buffer helps accommodate any unanticipated variance and ensures our study has enough statistical power to detect meaningful effects.


### Planned Sample
We plan to have a sample size of n = 108. For pre-screening, participants must speak English fluently to ensure comprehension in the task. Participants are recruited on Prolific online platform. 

### Materials

The materials were followed precisely as follows. "The auditory cues comprised basic-level category labels and environmental sounds for six categories: bird, dog, drum, guitar, motorcycle, and phone. For each category, we obtained two distinct environmental sound cues, e.g., <classical guitar strum>, <electric guitar strum>, and two separate images for each subordinate cate- gory, e.g., two electric guitars for <electric guitar strum>, two acoustic guitars for <electric guitar strum>. To control for cue variability, we also used two versions of each spoken category label: one pronounced by a female speaker, one by a male speaker. All auditory cues were equated in duration (600 ms.) and normalized in volume. The images were color photographs (four images per category). The materials, obtained from online repositories, are available for download at http://sapir.psych.wisc.edu/stimuli/ MotivatedCuesExp1A-1B.zip"(Edmiston & Lupyan, 2015).  

The link to our online experiment can be found here: https://ucsd-psych201a.github.io/edmiston2015/ 

### Procedure	

The procedure was followed precisely as in the original study for Experiment 1A. "On each trial participants heard a cue and saw a picture. We instructed participants to decide as quickly and accurately as possible if the picture they saw came from the same basic-level cate- gory as the word or sound they heard Participants were tested in individual rooms sitting approximately 2400 from a monitor such that images subtended 10  10°. Trials began with a 250 ms. fixation cross followed immediately by the auditory cue, delivered via headphones. The target image appeared centrally 1 s after the off- set of the auditory cue and remained visible until a response was made. Each participant completed 6 practice and 384 test trials. If the picture matched the auditory cue (50% of trials) participants were instructed to respond ‘Yes’ on a gaming controller (e.g., <cell- phone ring> or ‘‘phone’’ followed by a picture of any phone). Otherwise, they were to press ‘No’ (e.g., <cellphone ring> or ‘‘phone’’ followed by a dog). All factors (cue type, congruence) var- ied randomly within subjects. Auditory feedback (buzz or bleep) was given after each trial"(Edmiston & Lupyan, 2015). 


### Analysis Plan

**Clarify key analysis of interest here**  
A linear mixed regression model will be used to analyze response times for correct responses including "random intercepts and random slopes for within-subject factors and random intercepts for repeated items (unique trial types)"(Edmiston & Lupyan, 2015).  
In addition, significance tests using chi-square tests will be used to compare nested models, as was done in the original study, to assess the impact of factors with and without interest on response times. 

### Differences from Original Study

The original study used a remote controller.  The replication study will use the computer for responses and implement key responses to simulate buttons on controller. This should allow for accurate and quick responses. Participants were instructed to complete the study using headphones in a quiet environment. However, since the study was conducted online, experimenters had no control over participants' surroundings, which could introduce differences from the original study. Additionally, the original study controlled 

## Pilot A

For our Pilot A (with non-naive participants), we aimed to replicate the experimental paradigm described in the study. The GitHub page for our paradigm is linked below:

[Link to experimental paradigm](https://ucsd-psych201a.github.io/edmiston2015/)

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.
  
## Results

### Data preparation
We are replicating Experiment 1A from the paper. To clean the data we will remove incorrect responses or participants who failed attention checks.  As for data exclusion rules, we will follow the parameters set by the original study in which "Response times (RTs) shorter than 250 ms. or longer than 1500 ms. [will be] removed". This accounts for outliers that may skew results. There aren't any covariates mentioned in this experiment. 
	
```{r}
### Data Preparation

#### Load Relevant Libraries and Functions
library(tidyverse)
library(readr)
library(lme4)

#### Import data
#replace this with your own path (for now)
folder_path <- "/Users/jennabrooks/Documents/GitHub/edmiston2015"
csv_files <- list.files(folder_path, pattern = "*.csv", full.names = TRUE)
df_list <- lapply(csv_files, read_csv)
combined_df <- bind_rows(df_list)

#### Data exclusion / filtering
#exclude 'No' trials 
combined_df <- combined_df %>%
  mutate(response = as.character(response)) %>%
  filter(response == "y")
#exclude practice trials 
combined_df <- combined_df %>%
  filter(exp_part == "actual")

#rename "sound_subtype" to "cue"
combined_df <- combined_df %>%
  rename(cue = sound_subtype)

#create congruency column 
combined_df <- combined_df %>%
  mutate(congruency = case_when(
    cue == "label" ~ "label",
    img_subtype %in% c("song", "york", "bongo", "acoustic", "harley", "rotary") & sound_version == "A" ~ "incongruent",
    TRUE ~ "congruent"
  ))


#filter reaction time 
combined_df <- combined_df %>%
  filter(rt >250, rt <1500)

#### Prepare data for analysis - create columns etc.
combined_df <- combined_df %>%
  select(rt, ID, sound_category,cue, congruency)
```

### Confirmatory analysis

A linear mixed regression model will be used to analyze response times for correct responses including "random intercepts and random slopes for within-subject factors and random intercepts for repeated items (unique trial types)"(Edmiston & Lupyan, 2015).  
In addition, significance tests using chi-square tests will be used to compare nested models, as was done in the original study, to assess the impact of factors with and without interest on response times. 

Here is the link to the data we have collected for Pilot A so far: https://github.com/ucsd-psych201a/edmiston2015/tree/main/data Feedback from participants includes adding more attention checks and specifying in the instructions to use a laptop or computer for this study. We would also like to add a trial counter that allows participants to see their progress in the study.  

*Side-by-side graph with original graph is ideal here*

### Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
